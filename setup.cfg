[metadata]
name = crawlerstack_proxypool
version = attr: crawlerstack_proxypool.__version__
author = huagang
author_email = huagang517@126.com
url = https://github.com/crawlerstack/crawlerstack-proxypool
description = IP addresses proxy pool
keywords = ['proxypool']
long_description = file: README.md
long_description_content_type = text/markdown
license = MIT
classifiers =
    Operating System :: OS Independent
    Programming Language :: Python :: 3.7

[options]
python_requires > = 3.7
include_package_data = True
packages = find:
package_dir =
    = src
install_requires =
    dynaconf
    redis
    scrapy
    stevedore
    pydantic
    fake_useragent

[options.entry_points]
;console_scripts =

crawlerstack_proxypool.spider.parsers_driver =
    html = crawlerstack_proxypool.core.parsers:HtmlParser
    json = crawlerstack_proxypool.core.parsers:JsonParser
    text = crawlerstack_proxypool.core.parsers:TextParser

crawlerstack_proxypool.spider.checker_driver =
    anonymous = crawlerstack_proxypool.core.checkers:AnonymousChecker
    keywords = crawlerstack_proxypool.core.checkers:KeyWordsChecker

[options.packages.find]
where = src

[options.package_data]
crawlerstack_proxypool.config = settings.yml

[options.data_files]
etc/crawlerstack/proxypool = src/crawlerstack_proxypool/config/settings.yml

[tool:pytest]
testpaths = tests
python_files = tests.py test_*.py *_tests.py
